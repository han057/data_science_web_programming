{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCY ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import requests\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the stop words and add rt(retweet) as stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words(\"english\"))\n",
    "stopWords.add('rt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"tweet\").setMaster(\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function toSetOfWords that take the words from the tweet and remove all the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSetOfWords(tweet):\n",
    "    return (set(tweet.lower().replace('\\\\n','').split())-stopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take every tweet and split it in tuples counting by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSet(tweet):    \n",
    "    wordCount = set()\n",
    "    for word in tweet:\n",
    "        wordCount.add((word, 1))\n",
    "    return wordCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate pairs using frequentItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubset(t, size, frequentItems):\n",
    "    subSetsFromBasket = set()\n",
    "    combinations = itertools.combinations(t, size)\n",
    "    for subset in combinations:\n",
    "        #print(\"{} {} - {} {}\".format(subset[0], subset[0] in frequentItems, subset[1], subset[1] in frequentItems))\n",
    "        if subset[0] in frequentItems and subset[1] in frequentItems:\n",
    "            #print(\"SIIIII\")\n",
    "            subSetsFromBasket.add((subset, 1))\n",
    "    return subSetsFromBasket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solr_result_as_string(query):\n",
    "    result = requests.get(\"http://localhost:8983/solr/twitter/select?q=*:*\")\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"file:///home/han/tweettextall.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetSetOfWords = data.map(toSetOfWords)\n",
    "tweetWords = tweetSetOfWords.flatMap(toSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'2019',\n",
       "  '@gahbrielle_:',\n",
       "  'almost',\n",
       "  'it’s',\n",
       "  'leaving',\n",
       "  'marvel',\n",
       "  'movie?',\n",
       "  'right',\n",
       "  'still',\n",
       "  'theater',\n",
       "  'y’all'},\n",
       " {'5',\n",
       "  'bad',\n",
       "  'christmas',\n",
       "  'chunk',\n",
       "  'die',\n",
       "  'hacky',\n",
       "  'hard',\n",
       "  \"i'm\",\n",
       "  'louis',\n",
       "  'minute',\n",
       "  'movie.',\n",
       "  'really',\n",
       "  'set',\n",
       "  'surprised',\n",
       "  'whether'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetSetOfWords.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('right', 1),\n",
       " ('y’all', 1),\n",
       " ('2019', 1),\n",
       " ('marvel', 1),\n",
       " ('almost', 1),\n",
       " ('@gahbrielle_:', 1),\n",
       " ('movie?', 1),\n",
       " ('theater', 1),\n",
       " ('leaving', 1),\n",
       " ('it’s', 1),\n",
       " ('still', 1),\n",
       " ('really', 1),\n",
       " ('set', 1),\n",
       " ('bad', 1),\n",
       " ('whether', 1),\n",
       " ('hacky', 1),\n",
       " ('movie.', 1),\n",
       " ('louis', 1),\n",
       " ('5', 1),\n",
       " ('die', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetWords.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589156\n",
      "58915.600000000006\n"
     ]
    }
   ],
   "source": [
    "transactionCount = data.count()\n",
    "print(transactionCount)\n",
    "minSupport = transactionCount * 0.1\n",
    "print(minSupport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducedWordsRdd = tweetWords.reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "singletonSupport = dict()\n",
    "for s in reducedWordsRdd.collect():\n",
    "    singletonSupport[s[0]]= s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequentItems = reducedWordsRdd.filter(lambda w: w[1] >= minSupport).map(lambda w: w[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequentItems = set(frequentItems)\n",
    "frequentItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemPairs = tweetSetOfWords.flatMap(lambda t: getSubset(t, 2, frequentItems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemPairs.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemPairsCount = itemPairs.reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('movie', 'literally'), 72),\n",
       " (('“us”', 'proud'), 61),\n",
       " (('h…', 'movie??'), 61),\n",
       " (('family', 'version'), 69),\n",
       " (('version', 'soooo'), 61)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemPairsCount.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequentItemPairs = itemPairsCount.filter(lambda w: w[1] >= minSupport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('movie', 'literally'), 72),\n",
       " (('“us”', 'proud'), 61),\n",
       " (('h…', 'movie??'), 61),\n",
       " (('family', 'version'), 69),\n",
       " (('version', 'soooo'), 61)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequentItemPairs.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setSupportAndConfidence(x):\n",
    "    s = x[1]/transactionCount\n",
    "    return (x[0], s, s/singletonSupport[x[0][0]], s/singletonSupport[x[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "supports = frequentItemPairs.map(setSupportAndConfidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('movie', 'literally'), 0.144, 0.0004542586750788643, 0.0019459459459459458),\n",
       " (('“us”', 'proud'), 0.122, 0.002, 0.0017428571428571428),\n",
       " (('h…', 'movie??'), 0.122, 0.0019677419354838708, 0.002),\n",
       " (('family', 'version'), 0.138, 0.0019166666666666668, 0.002),\n",
       " (('version', 'soooo'), 0.122, 0.0017681159420289854, 0.002)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supports.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
